# main/rag_service.py

import pickle, faiss, os
# from langchain_community import OpenAIEmbeddings, ChatOpenAI # ìµœì‹  langchain-openai ì‚¬ìš©
# from langchain_community.vectorstores import FAISS
# from langchain.chains import RetrievalQA
# from langchain.prompts import PromptTemplate
# from konlpy.tag import Okt
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.docstore.document import Document
# from langchain_community.embeddings import OpenAIEmbeddings
# from langchain.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings
# from langchain_community.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
# from langchain_community.chat_models import ChatOpenAI
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain.prompts import PromptTemplate
import re
# ... (ì „ì²˜ë¦¬ í•¨ìˆ˜: clean_text, extract_pos, remove_stopwords ì •ì˜)

# API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œí•˜ê±°ë‚˜, ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
# settings.pyì— API_KEYë¥¼ ì„¤ì •í•˜ê³  os.environ.get('API_KEY')ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
OPENAI_API_KEY = "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" # ì‹¤ì œ í‚¤ ì…ë ¥
import re
from konlpy.tag import Okt

okt = Okt()

def clean_text(text):
    text = re.sub('[^ê°€-í£a-zA-Z0-9.\s]', '', text)
    return re.sub(' +', ' ', text).strip()

def extract_pos(text):
    if not isinstance(text, str) or not text.strip():
        return ""
    pos_tags = okt.pos(text, norm=True, stem=True)
    wanted_pos = ['Noun', 'Verb', 'Adjective']
    return ' '.join([word for word, pos in pos_tags if pos in wanted_pos])

def remove_stopwords(text):
    stopwords = ['í•˜ë‹¤','ìˆë‹¤','ê°™ë‹¤','ìë‹¤','ì•Šë‹¤','ë˜ë‹¤','ì“°ë‹¤','ì´ë‹¤','ì§„ì§œ','ì¨ë‹¤','ë“¤ë‹¤','ë˜ì–´ë‹¤','ë„ˆë¬´','ê°™ì•„ìš”','ê·¸ë˜ì„œ','ê·¸ë¦¬ê³ ']
    return ' '.join([w for w in text.split() if w not in stopwords])
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"#ì„ì‹œ
def initialize_qa_chain():
    """RAG ì²´ì¸ì„ ì„œë²„ ì‹œì‘ ì‹œ ë‹¨ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # 1) ë¡œì»¬ íŒŒì¼ ê²½ë¡œ ì„¤ì • (manage.py ìœ„ì¹˜ ê¸°ì¤€)
        index_path = os.path.join("main", "rag_model", "cosmetic_faiss.index")
        data_path = os.path.join("main/rag_model","cosmetic_data2.pkl")
        if not os.path.exists(index_path):
            print("[DEBUG] S3ì—ì„œ RAG íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            os.makedirs("main/rag_model/faiss_index", exist_ok=True) 
            s3 = boto3.client('s3')
            
            s3.download_file(S3_BUCKET_NAME, S3_FAISS_KEY, index_path)
            s3.download_file(S3_BUCKET_NAME, S3_PKL_KEY, data_path) # PKL íŒŒì¼ë„ S3ì— ì˜¬ë ¤ì•¼ í•¨
            print("[DEBUG] S3 ë‹¤ìš´ë¡œë“œ ì™„ë£Œ.")
        index = faiss.read_index("main/rag_model/faiss_index/cosmetic_faiss.index")
        
        with open("main/rag_model/faiss_index/cosmetic_data2.pkl", "rb") as f:
            data = pickle.load(f)
        texts = data["texts"]
        metadata = data["metadata"]
        docs = []
        for i in range(len(texts)):
            review_text = texts[i]
            meta = metadata[i]
            
            # ğŸŒŸ í•µì‹¬ ìˆ˜ì •: metadataì˜ ì¤‘ìš” ì •ë³´ë¥¼ reviewì™€ ê²°í•©í•˜ì—¬ page_contentì— ë„£ìŠµë‹ˆë‹¤.
            # ì´ë ‡ê²Œ í•´ì•¼ 'acne', 'í•„ìˆ˜' ê°™ì€ í‚¤ì›Œë“œê°€ ì„ë² ë”© ë²¡í„°ì— ë°˜ì˜ë©ë‹ˆë‹¤.
            enhanced_content = (
                f"ì œí’ˆëª…: {meta.get('product_name', 'N/A')}. "
                f"í”¼ë¶€ê³ ë¯¼_ìœ í˜•: {meta.get('type', 'N/A')}. "
                f"ì¶”ì²œë“±ê¸‰: {meta.get('grade', 'N/A')}. "
                f"ë¦¬ë·°: {review_text}"
            )

            doc = Document(page_content=enhanced_content, metadata=meta)
            docs.append(doc)
        # 2ï¸âƒ£ Documentë¡œ ë³€í™˜
        # docs = [Document(page_content=texts[i], metadata=metadata[i]) for i in range(len(texts))]

        # 3ï¸âƒ£ Docstore êµ¬ì„±
        docstore = InMemoryDocstore({str(i): docs[i] for i in range(len(docs))})
        index_to_docstore_id = {i: str(i) for i in range(len(docs))}

        # 3) ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=OPENAI_API_KEY)
        # FAISS.from_embeddings ëŒ€ì‹ , ë¡œë“œëœ indexë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
        vectorstore = FAISS(
            embedding_function=embeddings,
            index=index,
            docstore=docstore,
            index_to_docstore_id=index_to_docstore_id,
        )

        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

        # 4) LLM + í”„ë¡¬í”„íŠ¸ ì„¸íŒ…
        # template = """
        # ë‹¹ì‹ ì€ í™”ì¥í’ˆ ì¶”ì²œ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.
        # ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ **ë¦¬ë·° ë° ì œí’ˆ ì •ë³´(context)**ì…ë‹ˆë‹¤.
        # ì´ ì •ë³´(context)ì— **í¬í•¨ëœ ë‚´ìš©ë§Œ** ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        # ë§Œì•½ ê´€ë ¨ ë‚´ìš©ì´ contextì— ì—†ê±°ë‚˜ ë¶ˆì¶©ë¶„í•˜ë©´,
        # "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

        # === ê´€ë ¨ ë¦¬ë·° ë° ì œí’ˆ ë°ì´í„° ===
        # {context}

        # === ì‚¬ìš©ì ì§ˆë¬¸ ===
        # {question}

        # ìœ„ì˜ contextì— ê·¼ê±°í•˜ì—¬, 
        # í”¼ë¶€ ê³ ë¯¼ì— ë§ëŠ” í™”ì¥í’ˆì„ ì¶”ì²œí•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
        # """
        # template="""
        #     ë‹¹ì‹ ì€ í”¼ë¶€ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì˜ **í”¼ë¶€ ê³ ë¯¼ ìœ í˜•(type)**ê³¼ **í•„ìš”í•œ ê°œì„  ë“±ê¸‰(grade)**ì— ë§ì¶°, ì œê³µëœ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ í™”ì¥í’ˆì„ ì¶”ì²œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        #     ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ë•Œ, ë‹¤ìŒì˜ **í”¼ë¶€ ê³ ë¯¼ ìœ í˜• ë§¤í•‘ ê·œì¹™**ì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤.
        #     - pigment: ìƒ‰ì†Œì¹¨ì°©
        #     - dry: ì…ìˆ  ê±´ì¡° ë˜ëŠ” ê±´ì¡°
        #     - pore: ëª¨ê³µ
        #     - wrinkle: ì£¼ë¦„

        #     === ê´€ë ¨ ë¦¬ë·° ë° ì œí’ˆ ë°ì´í„° (Context) ===
        #     {context}

        #     === ì‚¬ìš©ì ì§ˆë¬¸ ===
        #     {question}

        #     ---

        #     ### ë‹µë³€ ì§€ì¹¨

        #     1.  **Context ì§‘ì¤‘**: ë‹µë³€ì€ ë°˜ë“œì‹œ **{context}** ë‚´ì— í¬í•¨ëœ **ì œí’ˆëª…, í”¼ë¶€ê³ ë¯¼ ìœ í˜•, ì¶”ì²œë“±ê¸‰, ì£¼ìš” ì„±ë¶„, ë¦¬ë·°** ì •ë³´ë¥¼ ê·¼ê±°ë¡œ í•©ë‹ˆë‹¤.
        #     2.  **ë“±ê¸‰ ìµœìš°ì„ **: ì‚¬ìš©ì ì§ˆë¬¸ì— 'í•„ìˆ˜', 'ê¶Œê³ ', 'ì˜ˆë°©'ê³¼ ê°™ì€ **ë“±ê¸‰ ì •ë³´ê°€ í¬í•¨**ë˜ì–´ ìˆë‹¤ë©´, Context ë‚´ì—ì„œ í•´ë‹¹ ë“±ê¸‰ì— ë§ëŠ” ì œí’ˆì„ ìµœìš°ì„ ìœ¼ë¡œ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.
        #     3.  **êµ¬ì²´ì ì¸ ì´ìœ **: ì¶”ì²œ í™”ì¥í’ˆì˜ ì´ë¦„ê³¼ í•¨ê»˜, Context ë‚´ì˜ **ì¶”ì²œë“±ê¸‰ ë° ì£¼ìš” ì„±ë¶„ì„ ì¸ìš©**í•˜ì—¬ ì¶”ì²œ ì´ìœ ë¥¼ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
        #     4.  **ì •ë³´ ë¶€ì¡± ì‹œ**: Contextì— í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìœ¼ë©´, "ì£„ì†¡í•˜ì§€ë§Œ, í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì œí’ˆ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
        # """
        template = """
ë‹¹ì‹ ì€ **í”¼ë¶€ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸**ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì œê³µëœ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ í”¼ë¶€ ê³ ë¯¼ê³¼ í•„ìš”í•œ ê°œì„  ë“±ê¸‰ì— ë§ëŠ” **ê°€ì¥ êµ¬ì²´ì ì¸** í™”ì¥í’ˆì„ ì¶”ì²œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ë•Œ, ë‹¤ìŒì˜ **í”¼ë¶€ ê³ ë¯¼ ìœ í˜• ë§¤í•‘ ê·œì¹™**ì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤.
            - pigment: ìƒ‰ì†Œì¹¨ì°©
            - dry: ì…ìˆ  ê±´ì¡° ë˜ëŠ” ê±´ì¡°
            - pore: ëª¨ê³µ
            - wrinkle: ì£¼ë¦„
            - elastic: íƒ„ì„±
=== ê´€ë ¨ ë¦¬ë·° ë° ì œí’ˆ ë°ì´í„° (Context) ===
{context}

=== ì‚¬ìš©ì ì§ˆë¬¸ ===
{question}

---

### ë‹µë³€ ì§€ì¹¨ (ë°˜ë“œì‹œ ë‹¤ìŒ 4ê°€ì§€ ê·œì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¥´ì„¸ìš”)

1.  **Context ê¸°ë°˜ ë‹µë³€ (ìœ ì¼í•œ ê·¼ê±°)**: ë‹µë³€ì€ ë°˜ë“œì‹œ **{context}** ë‚´ì— í¬í•¨ëœ **ì œí’ˆëª…, í”¼ë¶€ê³ ë¯¼ ìœ í˜•, ì¶”ì²œë“±ê¸‰, ì£¼ìš” ì„±ë¶„, ë¦¬ë·°** ì •ë³´ë¥¼ ê·¼ê±°ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤. Contextë¥¼ ë²—ì–´ë‚œ ì¼ë°˜ ì§€ì‹ì´ë‚˜ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

2.  **ë¶€ìœ„/ìœ í˜• ìµœìš°ì„ **: ì‚¬ìš©ì ì§ˆë¬¸ì— **íŠ¹ì • ë¶€ìœ„ ë˜ëŠ” ê³ ë¯¼ ìœ í˜•** (ì˜ˆ: ëª¨ê³µ, ì£¼ë¦„, ì…ìˆ  ê±´ì¡°, ìƒ‰ì†Œì¹¨ì°©)ì— ëŒ€í•œ ì–¸ê¸‰ì´ ìˆì„ ê²½ìš°, Context ë‚´ì—ì„œ í•´ë‹¹ ìœ í˜•ì´ ëª…ì‹œëœ ì œí’ˆì„ ìµœìš°ì„ ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

3.  **êµ¬ì²´ì ì¸ ì¶”ì²œ ê°•ì œ**: ì¶”ì²œí•˜ëŠ” í™”ì¥í’ˆì˜ ì´ë¦„ê³¼ í•¨ê»˜, Context ë‚´ì˜ ì¶”ì²œë“±ê¸‰(í•„ìˆ˜/ê¶Œê³ /ì˜ˆë°©), ê·¸ë¦¬ê³  ë¦¬ë·° ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ì¶”ì²œ ì´ìœ ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

4.  **ì •ë³´ ë¶€ì¡± ì‹œ**: Contextì— í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì „í˜€ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë‹µë³€ ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´, **"ì£„ì†¡í•˜ì§€ë§Œ, í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì œí’ˆ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."**ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
"""
        prompt = PromptTemplate(input_variables=["context", "question"], template=template)
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, api_key=OPENAI_API_KEY)

        # 5) QA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=retriever, 
            chain_type="stuff", 
            chain_type_kwargs={"prompt": prompt}
        )
        return qa_chain
    
    except Exception as e:
        print(f"RAG Chain ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None
def preprocess_query(query):

    text = clean_text(query)

    text = extract_pos(text)

    text = remove_stopwords(text)

    return text
# ì „ì—­ ë³€ìˆ˜ë¡œ ì²´ì¸ ì €ì¥

# global_qa_chain = None
